# -*- coding: utf-8 -*-
"""rekomendasi film

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mcLNYFMMjuzRrtRpNaPaiL4cTUzFitEV
"""

import pandas as pd
import numpy as np
import ast
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse.linalg import svds
from sklearn.feature_extraction.text import TfidfVectorizer

#Download data dari kaggle
import kagglehub

# Download latest version
path = kagglehub.dataset_download("rounakbanik/the-movies-dataset")
print("Path to dataset files:", path)

# Path to dataset files: /root/.cache/kagglehub/assets/rounakbanik/the-movies-dataset/current
movies_metadata_path = path + '/movies_metadata.csv'
credits_path = path + '/credits.csv'
keywords_path = path + '/keywords.csv'
ratings_path = path + '/ratings.csv'
links_path = path + '/links.csv'
links_small_path = path + '/links_small.csv'
ratings_small_path = path + '/ratings_small.csv'

import pandas as pd

# Load the datasets into pandas DataFrames
movies_metadata_df = pd.read_csv(movies_metadata_path, low_memory=False, nrows=10000)
credits_df = pd.read_csv(credits_path)
keywords_df = pd.read_csv(keywords_path)
ratings_df = pd.read_csv(ratings_path)
ratings_df = ratings_df[ratings_df['userId'] <= 1000]
links_df = pd.read_csv(links_path)
links_small_df = pd.read_csv(links_small_path)
ratings_small_df = pd.read_csv(ratings_small_path)

# Calculate and print the number of unique rows in each dataset
print(f"Jumlah data unik di movies_metadata.csv: {len(movies_metadata_df.drop_duplicates())}")
print(f"Jumlah data unik di credits.csv: {len(credits_df.drop_duplicates())}")
print(f"Jumlah data unik di keywords.csv: {len(keywords_df.drop_duplicates())}")
print(f"Jumlah data unik di ratings.csv: {len(ratings_df.drop_duplicates())}")
print(f"Jumlah data unik di links.csv: {len(links_df.drop_duplicates())}")
print(f"Jumlah data unik di links_small.csv: {len(links_small_df.drop_duplicates())}")
print(f"Jumlah data unik di ratings_small.csv: {len(ratings_small_df.drop_duplicates())}")

plt.figure(figsize=(8,5))
sns.histplot(movies_metadata_df['vote_average'].dropna(), bins=20, kde=True)
plt.title('Distribusi Vote Average Film')
plt.xlabel('Vote Average')
plt.ylabel('Jumlah Film')
plt.show()

plt.figure(figsize=(8,5))
sns.countplot(x='rating', data=ratings_df)
plt.title('Distribusi Rating Pengguna')
plt.xlabel('Rating')
plt.ylabel('Jumlah')
plt.show()

import ast
# Select relevant columns and handle missing overview
movies_metadata_df = movies_metadata_df[['id', 'title', 'overview', 'genres']].dropna(subset=['overview'])
# Clean the 'id' column to remove decimals
movies_metadata_df['id'] = movies_metadata_df['id'].astype(str).str.split('.').str[0]

# Ensure 'id' columns are strings for merging
credits_df['id'] = credits_df['id'].astype(str)
keywords_df['id'] = keywords_df['id'].astype(str)

# Merge the dataframes
# Corrected variable name from 'credits' to 'credits_df'
movies = movies_metadata_df.merge(credits_df, on='id').merge(keywords_df, on='id')

# Helper function to extract the director's name from the crew list
def get_director(crew):
    # Safely evaluate the string representation of the list
    try:
        crew_list = ast.literal_eval(crew)
        if isinstance(crew_list, list):
            for person in crew_list:
                if isinstance(person, dict) and person.get('job') == 'Director':
                    return person.get('name', '')
    except (ValueError, SyntaxError):
        pass # Handle cases where string is not a valid list representation
    return ''

# Helper function to extract names from a list of dictionaries
def get_list(obj):
    # Safely evaluate the string representation of the list
    try:
        obj_list = ast.literal_eval(obj)
        if isinstance(obj_list, list):
             return [item.get('name', '') for item in obj_list if isinstance(item, dict)]
    except (ValueError, SyntaxError):
        pass # Handle cases where string is not a valid list representation
    return []


# Apply the helper functions to extract relevant information
movies['cast'] = movies['cast'].apply(lambda x: get_list(x)[:3]) # Get top 3 cast members
movies['crew'] = movies['crew'].apply(get_director) # Get the director
movies['keywords'] = movies['keywords'].apply(get_list) # Get all keywords
movies['genres'] = movies['genres'].apply(get_list) # Get all genres

# Create the "soup" string for content-based filtering
movies['soup'] = movies['overview'] + ' ' + movies['crew'] + ' ' + \
                 movies['cast'].apply(lambda x: ' '.join(x)) + ' ' + \
                 movies['genres'].apply(lambda x: ' '.join(x)) + ' ' + \
                 movies['keywords'].apply(lambda x: ' '.join(x))

tfidf = TfidfVectorizer(stop_words='english', max_features=5000)
tfidf_matrix = tfidf.fit_transform(movies['soup'])
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
indices = pd.Series(movies.index, index=movies['title']).drop_duplicates()

def content_recommend(title, cosine_sim=cosine_sim):
    if title not in indices:
        return ["Judul tidak ditemukan"]
    idx = indices[title]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:11]
    movie_indices = [i[0] for i in sim_scores]
    return movies['title'].iloc[movie_indices].tolist()

print("\nTop 10 Rekomendasi Film Berdasarkan Konten untuk 'Toy Story':")
print(content_recommend('Toy Story'))

print("\nTop 10 Rekomendasi Film Berdasarkan Konten untuk 'The Dark Knight Rises':")
print(content_recommend('The Dark Knight Rises'))

ratings = ratings_df.merge(links_df, on='movieId').dropna(subset=['tmdbId'])
ratings['tmdbId'] = ratings['tmdbId'].astype(int).astype(str)

# Aggregate duplicate ratings for the same user and movie
# This handles cases where a user might have rated the same movie multiple times
ratings = ratings.groupby(['userId', 'tmdbId'])['rating'].mean().reset_index()

R_df = ratings.pivot(index='userId', columns='tmdbId', values='rating').fillna(0)
R = R_df.values
user_ratings_mean = R.mean(axis=1)
R_demeaned = R - user_ratings_mean.reshape(-1, 1)

U, sigma, Vt = svds(R_demeaned, k=50)
sigma = np.diag(sigma)
preds = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.reshape(-1, 1)
preds_df = pd.DataFrame(preds, columns=R_df.columns)

movie_map = movies[['id', 'title']].drop_duplicates().set_index('id')

def collab_recommend(user_id, preds_df=preds_df, movies=movies, original_ratings=R_df):
    user_row = preds_df.iloc[user_id - 1]
    already_rated = original_ratings.iloc[user_id - 1]
    unrated = user_row[already_rated == 0].sort_values(ascending=False)
    top_movies = unrated.head(10).index
    return [movie_map.loc[mid]['title'] if mid in movie_map.index else 'Unknown' for mid in top_movies]

print("\nTop 10 Rekomendasi Film Berdasarkan Collaborative Filtering untuk Pengguna 1:")
print(collab_recommend(1))

print("\nTop 10 Rekomendasi Film Berdasarkan Collaborative Filtering untuk Pengguna 10:")
print(collab_recommend(10))

from sklearn.metrics import mean_squared_error

# Buat train/test split manual
mask = np.random.rand(len(ratings)) < 0.8
train_ratings = ratings[mask]
test_ratings = ratings[~mask]

# Prediksi nilai rating dari test set
test_df = test_ratings.copy()
user_id_map = {uid: idx for idx, uid in enumerate(R_df.index)}
test_df['pred'] = test_df.apply(
    lambda row: preds_df.loc[user_id_map.get(row['userId'], 0)].get(str(int(row['tmdbId'])), np.nan), axis=1)

rmse = np.sqrt(mean_squared_error(test_df['rating'], test_df['pred']))
print(f"RMSE Collaborative Filtering: {rmse:.4f}")

# Visualisasi distribusi rating
plt.figure(figsize=(8, 5))
sns.histplot(ratings['rating'], bins=10, kde=True)
plt.title('Distribusi Rating Pengguna')
plt.xlabel('Rating')
plt.ylabel('Frekuensi')
plt.show()

from IPython.display import display
import ipywidgets as widgets

def show_content_based():
    input_film = widgets.Text(value='The Avengers', placeholder='Masukkan judul film', description='Film:')
    button = widgets.Button(description="Rekomendasikan")
    output = widgets.Output()

    def on_button_clicked(b):
        with output:
            output.clear_output()
            hasil = content_recommend(input_film.value)
            print("Rekomendasi berdasarkan film:", input_film.value)
            for i, film in enumerate(hasil, 1):
                print(f"{i}. {film}")

    button.on_click(on_button_clicked)
    display(input_film, button, output)

def show_collab_based():
    input_user = widgets.BoundedIntText(value=1, min=1, max=610, step=1, description='User ID:')
    button = widgets.Button(description="Rekomendasikan")
    output = widgets.Output()

    def on_button_clicked(b):
        with output:
            output.clear_output()
            hasil = collab_recommend(input_user.value)
            print(f"Rekomendasi untuk user {input_user.value}:")
            for i, film in enumerate(hasil, 1):
                print(f"{i}. {film}")

    button.on_click(on_button_clicked)
    display(input_user, button, output)

show_content_based()
show_collab_based()